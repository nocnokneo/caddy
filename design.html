<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>Caddy: Design</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Caddy
   </div>
   <div id="projectbrief">A 2005 Roborodentia entry with vision and path planning capability</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.1.2 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="annotated.html"><span>Data&#160;Structures</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Data Structures</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Macros</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Design </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="team_process"></a>
Collaborative Team Process</h1>
<p>The team for this project was formed from interested members of the the <a href="http://robotics.ee.calpoly.edu/">Cal Poly Robotics Club</a>.</p>
<p>To organize the tasks and identify critical paths in the (short) project time line, we used <a href="http://www.ganttproject.biz/">GanttProject</a> to create a Gantt chart.</p>
<p>For code control and collaboration we used Concurrent Versions System (CVS). Since this project had a competitive nature, we chose to setup and host our own private CVS server rather than use a free, Internet-based hosting service.</p>
<p>Between face-to-face team meetings we used Drupal to host a private forum for discussing ideas, sharing progress, etc.</p>
<p>The inline code documentation and this project report were both managed using <a href="http://doxygen.org">Doxygen</a>. Keeping the documentation in plain text and means that the documentation can be version controlled the very same way as the source code. The documentation also tends to stay more up to date since it can be more conveniently updated at the same time as the source code.</p>
<h1><a class="anchor" id="system_arch"></a>
System Architecture</h1>
<p>When taking a holistic look at the project goals and requirements, it is clear that a camera-based vision system can satisfy line following, junction detection and ball-finding requirements. The image processing required for these task can all be done with a camera that is low resolution, low power, and low cost. The ball finding task, in particular, has few other options that are both low cost and simple to implement. The <a href="http://cmucam.org/projects/cmucam2">CMUcam2</a> developed by students at Carnegie Mellon University and sold through distributors as a packaged vision system, met our needs well.</p>
<p>Since the CMUcam can handle all the computationally intensive image processing as well as drive 5 servo control outputs, our requirements on the main microcontroller were fairly relaxed. The most computationally demanding task for the main microcontroller is the shortest path algorithm, but with a relatively small map even this could be handled by a low-end microcontroller.</p>
<h1><a class="anchor" id="electrical_design"></a>
Electrical Design</h1>
<h2><a class="anchor" id="power_motor"></a>
Power Regulation and Motor Controller</h2>
<p>We opted to design and build our own power regulation and motor control circuitry over purchasing one of the more expensive off-the-shelf solutions. To ensure that we were not debugging software and electrical issues at the same time (difficult!) made sure to include robust regulation and decouple in the design. Our power sub-component power needs were:</p>
<ul>
<li>+5V regulated power for the ATMega32 and the rest of the electronics </li>
<li>+6-15V unregulated power for the CMUcam2 </li>
<li>+6V for each motor, controllable via logic-level signal</li>
</ul>
<p>Unregulated voltage was connected to the CMUcam2 (it had a built-in regulator) and to the motors. Although not ideal, connecting the motors to unregulated power meant we could save on cost by using a smaller, cheaper voltage regulator. We opted for a linear regulator to supply the +5V to the ATMega32 microcontroller.</p>
<p>In the choice between a linear regulator and a switching regulator, a linear was chosen over a switching regulator for the following reasons:</p>
<ul>
<li>Lower output noise - We wanted to take every precaution we could to ensure the EMF voltage generated by the motors did not affect the electronics.</li>
</ul>
<ul>
<li>Simpler to implement - Switching regulators typically require more passive components to filter the inherently higher noise they generate.</li>
</ul>
<ul>
<li>Cheaper</li>
</ul>
<p>Switching regulators are more efficient, however any efficiency gains would be dwarfed in comparison with the power demands of the unregulated components (DC motors and CMUcam2). The circuit diagram for our implementation is shown below:</p>
<div class="image">
<img src="power_sch.png" alt="power_sch.png"/>
<div class="caption">
Power regulation circuit</div></div>
<p>To control the motors via digital signal we used an H-bridge circuit. For added protection of the electronics from the back-EMF voltage of the motors, additional diodes were connected as shown in the schematic below.</p>
<div class="image">
<img src="motor_control_sch.png" alt="motor_control_sch.png"/>
<div class="caption">
Motor control circuit</div></div>
<p>The power regulation and motor control circuits were fabricated together on a single board using a copper-plated board, etching solution, and a laser print out of the circuit layout. We made sure to use polarized headers for all the connections to avoid making any reverse polarity mistakes (we still managed to make a couple!).</p>
<h2><a class="anchor" id="ir_break_beam"></a>
IR Break Beam</h2>
<p>To detect when a ball is within the grasp of the lift we had two options. Originally we thought that we could simply use the centroid tracking feature of the camera since we would have the camera facing down watching the line anyway. This turned out to be difficult for a couple reasons.</p>
<p>When the camera is configured to track a black line, glare from the overhead lighting and red golf balls have the same effect on what the camera sees – a gap in the line. This seemed like an easily surmountable problem at first. Just change modes whenever a gap is detected, determine if it is a ball or a glare, and act accordingly. As with any software program, introducing one seemingly small change has the potential to severely affect the rest of the system. This particular case was no exception. First, the CMUcam did not handle rapid mode/parameter changes well, taking longer than we expected to go from one mode to another. This lead to a failure in our finely tuned PID line tracking algorithm which relied on frequent, regular updates over time. We considered and experimented with some ways of solving this problem but none were the quick, elegant solution we were looking for.</p>
<p>With a fast approaching deadline and still much to do, we decided that the quickest way to solve the problem was to simply setup a break beam sensor in just the right position to detect when the lift mechanism should be raised. This was fast to implement and worked reliably.</p>
<p>Here is a schematic of our break beam circuit:</p>
<h2><a class="anchor" id="servo_reverser"></a>
Servo Reverser</h2>
<p>The mechanical design of Caddy required 6 servos:</p>
<ul>
<li>Ball pickup, left side </li>
<li>Ball pickup, right side </li>
<li>Boom control </li>
<li>Ball hopper </li>
<li>Tilt action </li>
<li>Pan action</li>
</ul>
<p>This meant that the original plan to use the five servo control outputs of the CMUcam would be inadequate.</p>
<p>The following approaches were considered for accommodating the 6th servo output:</p>
<ul>
<li><b>Mechanical:</b> Modify the mechanical design so that the ball pickup mechanism could be controlled by just one high-torque servo. Tyson had already done such an awesome job of designing the lift to be actuated by just one mechanical motion that this seemed like too much to ask.</li>
</ul>
<ul>
<li><b>Software:</b> Use some of the extra pins on the ATmega32 to generate a servo PWM signal. Unfortunately we were already using the two PWM peripherals on the ATmega32 so we would have to do this in software. We had limited timer resources on our chip and weren't sure how we might need to use them in the future so this was not an ideal solution.</li>
</ul>
<ul>
<li><b>Electrical:</b> Leverage the fact that the 2 servos controlling the ball pickup were the same signal, 180 degrees out of phase. This seemed like a perfect application for a simple 555 timer circuit.</li>
</ul>
<p>We decided to use the 555 timer approach. Using plans found online, we fabricated the board with a 4-pin header so that the circuit could easily be reused in the future.</p>
<h2><a class="anchor" id="wheel_encoders"></a>
Wheel Encoders</h2>
<p>The maneuvers needed at junctions and for the bonus ball pick up sequences needed to be accurate and repeatable. To achieve this we used a black and white encoder disk that we printed out and glued to the inside edge of each drive wheel. <a class="el" href="citelist.html#CITEREF_walters_dead_reckoning_2000">[1]</a></p>
<div class="image">
<img src="encoder_disc.png" alt="encoder_disc.png"/>
<div class="caption">
Reflective IR wheel encoder pattern</div></div>
<h1><a class="anchor" id="software_architecture"></a>
Software Architecture</h1>
<h2><a class="anchor" id="computing_platform"></a>
Computing Platform</h2>
<p>For our our computing platform we chose an ATmega32 microcontroller from Atmel's 8-bit AVR line of microcontrollers because it was C-programmable with free open-source tools and because we had a readily available development board, the ERE EMBMega32.</p>
<div class="image">
<img src="ere_embmega32.png" alt="ere_embmega32.png"/>
<div class="caption">
EMBMega32 development board from ERE CO.,LTD</div></div>
<h2><a class="anchor" id="line_tracking"></a>
PID Line Tracking</h2>
<p>To track the black electrical tape line, we implemented a proportional–integral–derivative (PID) controller. In PID theory, the output of a PID controller, <img class="formulaInl" alt="$c(t)$" src="form_0.png"/>, is defined as:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ c(t) = P_E e(t) + P_I \int e(t) dt + P_D \frac{de}{dt} \]" src="form_8.png"/>
</p>
<p>Where <img class="formulaInl" alt="$ e(t) $" src="form_2.png"/> is some error function and <img class="formulaInl" alt="$ P_E $" src="form_3.png"/>, <img class="formulaInl" alt="$ P_I $" src="form_4.png"/>, and <img class="formulaInl" alt="$ P_D $" src="form_5.png"/> are adjustment coefficients for the observed error, the integrated error and the derivative of the error, respectively. We define our error term:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ e(t) = \frac{dx}{dt} \]" src="form_9.png"/>
</p>
<p>By substitution, we get:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ c(t) = P_E \frac{dx}{dt} + P_I x(t) + P_D \frac{d^2x}{dt^2} \]" src="form_10.png"/>
</p>
<p>Broken down and interpretted for the task of line tracking, these terms are:</p>
<ul>
<li><img class="formulaInl" alt="$ P_E \frac{dx}{dt} \leftarrow $" src="form_12.png"/> How fast are we drifting from the center line? </li>
<li><img class="formulaInl" alt="$ P_I x(t) \leftarrow $" src="form_13.png"/> How far are we from from the center line? </li>
<li><img class="formulaInl" alt="$ P_D \frac{d^2x}{dt^2} \leftarrow $" src="form_14.png"/> How fast is the drift rate accelerating?</li>
</ul>
<p>Provided that there is a way to measure or compute each of these terms, this is a more robust form of the equation because it eliminates the integral term which can cause problems due to accumulated error.</p>
<p>The figure below shows how the camera was used to measure <img class="formulaInl" alt="$ P_E \frac{dx}{dt} $" src="form_15.png"/>:</p>
<div class="image">
<img src="line_tracking_dia.png" alt="line_tracking_dia.png"/>
<div class="caption">
Diagram of line tracking geometry (NOT to scale)</div></div>
<p>The drift rate is the slope of the black line with respect to the center line of the robot. For points <img class="formulaInl" alt="$ P_1 = (x_1,y_1) $" src="form_29.png"/> and <img class="formulaInl" alt="$ P_2 = (x_2,y_2) $" src="form_30.png"/> from the diagram above we define:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \frac{dx}{dt} = \frac{y_2-y_1}{x_2-x_1} \]" src="form_16.png"/>
</p>
<p>And for point <img class="formulaInl" alt="$ P_3 = (x_3,y_3) $" src="form_31.png"/> with constant, measurable value for <img class="formulaInl" alt="$ y_3 $" src="form_21.png"/> and for constant, measurable line center <img class="formulaInl" alt="$ x_{center} $" src="form_26.png"/></p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ x_3 = x_{center} - \frac{dx}{dt} (y_3 - y_1) + x_1; \]" src="form_28.png"/>
</p>
<p>Lastly, by storing the previously computed value of <img class="formulaInl" alt="$ \frac{dx}{dt} $" src="form_24.png"/>, we can compute the third term:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \frac{d^2x}{dt^2} = \frac{dx}{dt} - \frac{dx}{dt}_{previous} \]" src="form_25.png"/>
</p>
<p>The coefficients for each of these terms were determined by trial and error using a tethered remote and stored persistently in EEPROM.</p>
<h2><a class="anchor" id="maneuvering"></a>
Maneuvering</h2>
<p>When turning our bot by a certain number of ticks, we experienced overshoot despite actively applying DC motor braking. We addressed the problem with the following software solution.</p>
<p>After turning for the desired number of ticks, we applied braking and counted the number of excess ticks that occurred from the instant braking was commanded. After a fixed delay, we drove the wheels in the opposite direction for that same number of ticks.</p>
<p>This worked well for the most part, however, with different battery charges, turn amounts, and turn types, the amount of time to brake was never the same. If we did not brake the motors for a long enough delay, our bot would stop counting excess ticks and begin to drive the motors in the opposite direction, too soon. With our unsophisticated encoders that cannot detect the direction of wheel motion this resulted in "reverse ticks" being counted before the wheel had actually started moving in the reverse direction.</p>
<h2><a class="anchor" id="ball_detection"></a>
Ball Detection and Localization</h2>
<h2><a class="anchor" id="path_planning"></a>
Path Planning</h2>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Tue Mar 19 2013 00:10:30 for Caddy by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.1.2
</small></address>
</body>
</html>
