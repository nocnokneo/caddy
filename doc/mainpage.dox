/**

@mainpage Introduction

@section problem_summary Problem Summary

Caddy is a robot entered into the 2005 Roborodentia. Roborodentia is an annual
autonomous robotics competition held during Cal Poly's Open House by the IEEE
Computer Society. Robot entries must navigate a maze searching for three
randomly placed golf balls, collect them, and then deposit the balls in the
“nest” at the end of the maze. The 2005 competition also included a new
aspect. Two bonus balls were placed on a platform behind the wall in two
predetermined corners of the maze such that the top of the golf ball was flush
with the top of the wall.

@image html  arena.png "Arena map showing the two fixed bonus ball locations and the potential locations of the randomly placed ground balls"
@image latex arena.png "Arena map showing the two fixed bonus ball locations and the potential locations of the randomly placed ground balls" width=10cm

The competition scoring breakdown is as follows:

<table>
  <tr>
    <th>Point Value</th>
    <th>Task</th>
  </tr>
  <tr>
    <td>1</td>
    <td>Passing the first turn in the maze - Point A</td>
  </tr>
  <tr>
    <td>1</td>
    <td>Triggering “nest” solenoid by activating optical sensor - Point X</td>
  </tr>
  <tr>
    <td>3</td>
    <td>Touching each ground ball (1 point per ball)</td>
  </tr>
  <tr>
    <td>3</td>
    <td>Collecting and possessing each ground ball (1 point per ball)</td>
  </tr>
  <tr>
    <td>3</td>
    <td>Bringing each ground ball to “nest” - Area B (1 point per ball)</td>
  </tr>
  <tr>
    <td>9</td>
    <td>Placing each ground ball in “nest” - Point E (3 points per ball)</td>
  </tr>
  <tr>
    <td>10</td>
    <td>Collecting and possessing a bonus ball - 2 Yellow Balls (5 points per ball)</td>
  </tr>
  <tr>
    <td>6</td>
    <td>Placing a bonus ball in the “nest” (3 points per ball)</td>
  </tr>
  <tr>
    <td>36</td>
    <td>Total possible points</td>
  </tr>
</table>

In the case of a tie, the robot with the fastest time wins.

@htmlonly
<p>
The following sections document the Cal Poly Robotics Club entry "Caddy" for
the 2005 Roborodentia competition:
</p>
<ul>
<li><a href="goals.html">Goals</a></li>
<li><a href="design.html">Design</a></li>
<li><a href="conclusion.html">Conclusion</a></li>
<li><a href="appendix.html">Appendix</a></li>
</ul>

<p>
The content of this site is also available as a <a href="caddy.pdf">single pdf
report</a>.
</p>

@endhtmlonly

@page goals Goals and Requirements

The rules of the competition dictated a baseline set of goals that need to be
met to be successful:

@li <b>Line following</b> - The corridors of the maze were constructed with a
black electrical tape line down the center, meant as an aid for the autonomous
navigation of the pathways - and we saw no reason not to take advantage of it.

@li <b>Junction detection</b> - To navigate the maze, Caddy would need the
ability to detect when a junction was reach and to identify the type of
junction (e.g. "T" junction, straight-or-right-turn junction, etc).

@li <b>Ground ball collection</b> - The maximum score without collecting any
ground ball is 5 out of 36 possible points - so a ground ball collection
system is a must to score well.

@li <b>Bonus ball collection</b> - Since the scoring distribution weighted
bonus balls so heavily (16 of the 36 possible points are awarded for bonus
ball tasks), we also decided that Caddy would need bonus ball collection
capability in order to be competitive.

@li <b>Ball release-into-nest system</b> - For an additional 3 points per
ball, having the ability to release balls into the nest seemed worthwhile and
comparatively simple to implement.

In addition to this baseline set of goals, we decided to focus on the
autonomous aspect of the Roborodentia competition. In particular we wanted a
robot that could <em>actively adapt</em> to the random ball locations (unlike
any previous entry had ever done). This was the driver for an additional two
requirements:

@li <b>Path planning</b> - Caddy needed a way to map the arena and a shortest
path algorithm that could find the best path through a sequence of goals.

@li <b>Ball finding</b> - To make the best use of the path planning algorithm,
we needed a way to actively search for balls down untraveled corridors.

@page design Design

@section team_process Collaborative Team Process

The team for this project was formed from interested members of the the
<a href="http://robotics.ee.calpoly.edu/">Cal Poly Robotics Club</a>.

To organize the tasks and identify critical paths in the (short) project
time line, we used <a href="http://www.ganttproject.biz/">GanttProject</a>
to create a Gantt chart.

For code control and collaboration we used Concurrent Versions System
(CVS). Since this project had a competitive nature, we chose to setup and host
our own private CVS server rather than use a free, Internet-based hosting
service.

Between face-to-face team meetings we used Drupal to host a private forum for
discussing ideas, sharing progress, etc.

The inline code documentation and this project report were both managed using
<a href="http://doxygen.org">Doxygen</a>. Keeping the documentation in plain
text and means that the documentation can be version controlled the very same
way as the source code. The documentation also tends to stay more up to date
since it can be more conveniently updated at the same time as the source code.

@section system_arch System Architecture

When taking a holistic look at the project goals and requirements, it is
clear that a camera-based vision system can satisfy line following, junction
detection and ball-finding requirements. The image processing required for
these task can all be done with a camera that is low resolution, low power,
and low cost. The ball finding task, in particular, has few other options that
are both low cost and simple to implement. The <a
href="http://cmucam.org/projects/cmucam2">CMUcam2</a> developed by students
at Carnegie Mellon University and sold through distributors as a packaged
vision system, met our needs well.

Since the CMUcam can handle all the computationally intensive image processing
as well as drive 5 servo control outputs, our requirements on the main
microcontroller were fairly relaxed. The most computationally demanding task
for the main microcontroller is the shortest path algorithm, but with a
relatively small map even this could be handled by a low-end microcontroller.

@section electrical_design Electrical Design

@subsection power_motor Power Regulation and Motor Controller

We opted to design and build our own power regulation and motor control
circuitry over purchasing one of the more expensive off-the-shelf solutions.
To ensure that we were not debugging software and electrical issues at the
same time (difficult!) made sure to include robust regulation and decouple
in the design. Our power sub-component power needs were:

@li +5V regulated power for the ATMega32 and the rest of the electronics
@li +6-15V unregulated power for the CMUcam2
@li +6V for each motor, controllable via logic-level signal

Unregulated voltage was connected to the CMUcam2 (it had a built-in regulator)
and to the motors. Although not ideal, connecting the motors to unregulated
power meant we could save on cost by using a smaller, cheaper voltage
regulator. We opted for a linear regulator to supply the +5V to the ATMega32
microcontroller.

In the choice between a linear regulator and a switching regulator, a linear
was chosen over a switching regulator for the following reasons:

@li Lower output noise - We wanted to take every precaution we could to ensure
the EMF voltage generated by the motors did not affect the electronics.

@li Simpler to implement - Switching regulators typically require more passive
components to filter the inherently higher noise they generate.

@li Cheaper

Switching regulators are more efficient, however any efficiency gains would be
dwarfed in comparison with the power demands of the unregulated components (DC
motors and CMUcam2). The circuit diagram for our implementation is shown
below:

@image html  power_sch.png "Power regulation circuit"
@image latex power_sch.eps "Power regulation circuit" width=14cm

To control the motors via digital signal we used an H-bridge circuit. For
added protection of the electronics from the back-EMF voltage of the motors,
additional diodes were connected as shown in the schematic below.

@image html  motor_control_sch.png "Motor control circuit"
@image latex motor_control_sch.eps "Motor control circuit" width=17cm

The power regulation and motor control circuits were fabricated together on a
single board using a copper-plated board, etching solution, and a laser print
out of the circuit layout. We made sure to use polarized headers for all the
connections to avoid making any reverse polarity mistakes (we still managed to
make a couple!).

@subsection ir_break_beam IR Break Beam

In order to capture ground balls, Caddy needed a way to detect when a ball was
within the grasp of its lift mechanism.

Originally planned to use the centroid tracking feature of the camera since
the camera would always be facing down for line tracking during the times it
needed to detect ground balls. This turned out to be difficult mainly due to
the limitations of the camera. When the camera is configured to track a black
line, glare from the overhead lighting and red golf balls have the same effect
on what the camera detects – a gap in the line. We tried to simply change
modes whenever a gap was detected, determine if the gap was due to a glare or
a due to a ball, and then act accordingly. Unfortunately, the CMUcam did not
handle rapid mode and parameter changes well, taking too long to switch from
one mode to another. This lead to a failure in our carefully tuned PID line
tracking algorithm which relied on frequent, regular updates over time. We
considered and experimented with some ways of solving this problem but none
were the quick, elegant solution we were looking for.

With a fast approaching deadline, we opted for a quick, but less elegant,
solution. We installed an IR break beam sensor looking across the front of
the lift arm so that when the arm was down and fully open a ground ball would
break the beam as is passed under the arm.

@subsection servo_reverser Servo Reverser

The mechanical design of Caddy required 6 servos:

@li Ball pickup, left side
@li Ball pickup, right side
@li Boom control
@li Ball hopper
@li Tilt action
@li Pan action

This meant that the original plan to use the five servo control outputs of the
CMUcam would be inadequate.

The following approaches were considered for accommodating the 6th servo
output:

@li \b Mechanical: Modify the mechanical design so that the ball pickup
mechanism could be controlled by just one high-torque servo. The lift
mechanism had already been iteratively refined to the point that it could be
actuated by just one mechanical motion. Going this route would likely mean
some major rework of the mechanical design - not ideal since we were otherwise
happy with the mechanics of the robot.

@li \b Software: Use some of the extra pins on the ATmega32 to generate a
servo PWM signal. Unfortunately we were already using the two PWM peripherals
on the ATmega32 so we would have to do this in software. We had limited timer
resources on our chip and weren't sure how we might need to use them in the
future so this was not an ideal solution.

@li \b Electrical: Leverage the fact that the 2 servos controlling the ball
pickup were the same signal, 180 degrees out of phase. This seemed like a
perfect application for a simple 555 timer circuit.

Searching the Internet, we found we were not the only ones to think of using a
555 timer to create a servo reverser. Using the well documented plans from
C. Dane @cite dane_the_reverser we fabricated a board the size of a postage
stamp.

@subsection wheel_encoders Wheel Encoders

The maneuvers needed at junctions and for the bonus ball pick up sequences
needed to be accurate and repeatable. To achieve this we used a black and
white encoder disk that we printed out and glued to the inside edge of each
drive wheel. @cite walters_dead_reckoning_2000

@image html  encoder_disc.png "Reflective IR wheel encoder pattern"
@image latex encoder_disc.png "Reflective IR wheel encoder pattern" width=6cm

@todo information, photo, schematic

@section software_architecture Software Architecture

@subsection computing_platform Computing Platform

For our our computing platform we chose an ATmega32 microcontroller from
Atmel's 8-bit AVR line of microcontrollers because it was C-programmable with
free open-source tools and because we had a readily available development
board, the ERE EMBMega32.

@image html  ere_embmega32.png "EMBMega32 development board from ERE CO.,LTD"
@image latex ere_embmega32.png "EMBMega32 development board from ERE CO.,LTD" width=6cm

@subsection line_tracking PID Line Tracking

To track the black electrical tape line, we implemented a
proportional–integral–derivative (PID) controller. In PID theory, the output
of a PID controller, @f$c(t)@f$, is defined as:

@f[
c(t) = P_E e(t) + P_I \int e(t) dt + P_D \frac{de}{dt}
@f]

Where @f$ e(t) @f$ is some error function and @f$ P_E @f$, @f$ P_I @f$, and
@f$ P_D @f$ are adjustment coefficients for the observed error, the integrated
error and the derivative of the error, respectively. We define our error
term:

@f[
e(t) = \frac{dx}{dt}
@f]

By substitution, we get:

@f[
c(t) = P_E \frac{dx}{dt} + P_I x(t) + P_D \frac{d^2x}{dt^2}
@f]

Broken down and interpretted for the task of line tracking, these terms are:

@li @f$ P_E \frac{dx}{dt} \leftarrow @f$ How fast are we drifting from the center line?
@li @f$ P_I x(t) \leftarrow @f$ How far are we from from the center line?
@li @f$ P_D \frac{d^2x}{dt^2} \leftarrow @f$ How fast is the drift rate accelerating?

Provided that there is a way to measure or compute each of these terms, this
is a more robust form of the equation because it eliminates the integral term
which can cause problems due to accumulated error.

The figure below shows how the camera was used to measure @f$ P_E \frac{dx}{dt} @f$:

@image html  line_tracking_dia.png "Diagram of line tracking geometry (NOT to scale)"
@image latex line_tracking_dia.png "Diagram of line tracking geometry (NOT to scale)" width=14cm

The drift rate is the slope of the black line with respect to the center line
of the robot. For points @f$ P_1 = (x_1,y_1) @f$ and @f$ P_2 = (x_2,y_2) @f$
from the diagram above we define:

@f[
\frac{dx}{dt} = \frac{y_2-y_1}{x_2-x_1}
@f]

And for point @f$ P_3 = (x_3,y_3) @f$ with constant, measurable value for @f$
y_3 @f$ and for constant, measurable line center @f$ x_{center} @f$

@f[
x_3 = x_{center} - \frac{dx}{dt} (y_3 - y_1) + x_1;
@f]

Lastly, by storing the previously computed value of @f$ \frac{dx}{dt} @f$, we can
compute the third term:

@f[
\frac{d^2x}{dt^2} = \frac{dx}{dt} - \frac{dx}{dt}_{previous}
@f]

The coefficients for each of these terms were determined by trial and error
using a tethered remote and stored persistently in EEPROM.

@subsection maneuvering Maneuvering

When turning our bot by a certain number of ticks, we experienced overshoot
despite actively applying DC motor braking. We addressed the problem with the
following software solution.

After turning for the desired number of ticks, we applied braking and counted
the number of excess ticks that occurred from the instant braking was
commanded. After a fixed delay, we drove the wheels in the opposite direction
for that same number of ticks.

This worked well for the most part, however, with different battery charges,
turn amounts, and turn types, the amount of time to brake was never the
same. If we did not brake the motors for a long enough delay, our bot would
stop counting excess ticks and begin to drive the motors in the opposite
direction, too soon. With our unsophisticated encoders that cannot detect the
direction of wheel motion this resulted in "reverse ticks" being counted
before the wheel had actually started moving in the reverse direction.

@subsection ball_detection Ball Detection and Localization

@subsection path_planning Path Planning

@page conclusion Conclusion

@section future_work Future Work

@subsection regulated_motor_voltage Regulated Motor Voltage

If we end up working with higher voltage motors again, it may be worth losing
some voltage in order to send regulated voltage to the motors. This allows for
more consistent operation across fresh and low batteries. This should also
condition our batteries better, because the battery voltage can drop until the
regulator’s threshold is reached. As long as we drop the voltage down enough,
it should be obvious when batteries are dead. As the regulator cuts out, the
bot should slow down more dramatically. A common solution in ME 405
(mechatronics) is to regulate 14.4V down to 12V with an adjustable regulator
(LM1084) for each motor. One regulator was not able to provide enough current
for both motors. When driving the motors at the same pulse width, we were able
to see a difference in how straight the bot drove, if the motors received
voltages a few hundredths apart. Yet, just having the ability to precisely and
consistently set the voltage to the motors was very useful.

@subsection 16_pwm_motor_control 16-bit PWM Motor Control

Since we were using timer 1 (a 16-bit timer) for PWM, we could have used
16-bit PWM. 8-bit resolution seemed to be sufficient with the original 6 volts
motors, but when we switched to 12 volt motors, more precise control of the
PWM signal would likely have improved the PID line tracking. As it was, we had
to use a PID offset constant of 1 which means that we would have required
division to decrease the proportional coefficient parameter of our PID control
algorithm.

@subsection quadrature_wheel_encoders Quadrature Wheel Encoders

Quadrature wheel encoders would have required more mechanical work (to mount
the reflective IR sensors 90 degrees out-of-phase) and electrical work (wiring
for twice as many sensors) but it would have helped solve some challenges
with maneuvering the robot through precise sequences such as the bonus ball
pickup.

Quadrature encoders would have allowed us to perform overshoot correction
easily and accurately. 

@page appendix Appendix

@section gantt Gantt Chart

@image html  caddy_gantt.png "Caddy project gantt chart"
@image latex caddy_gantt.png "Caddy project gantt chart" width=17cm

@htmlinclude reference.html

@section contributions Individual Contributions

Caddy was a joint effort between Taylor Braun-Jones, Logan Kinde, Tyson
Messori, Scott Barlow, Michael Shelley, and Patrick McCarty. Primary
contributors were Taylor, Logan, and Tyson.

@image html  team_photo.png "Team Photo. Left to right: Logan Kinde, Tyson Messori, Taylor Braun-Jones, Scott Barlow, Michael Shelley, Patrick McCarty"
@image latex team_photo.png "Team Photo. Left to right: Logan Kinde, Tyson Messori, Taylor Braun-Jones, Scott Barlow, Michael Shelley, Patrick McCarty" width=12cm

@subsection taylor_contrib Contributions of Taylor Braun-Jones

Taylor was responsible for overall project coordination and administration
including:

@li Gantt chart creation and tracking
@li MESFAC grant proposal
@li Part ordering and budget management
@li Creation and administration of the code repository

Taylor's electrical and mechanical contributions include:

@li Custom-made battery packs from shrink wrap and five +1.2V rechargable NiMH
AA batteries

@li The design and implemenation of the bracket used to mount the CMUcam2 to
the panning servo

@li The concept and implementation of a detachable tethered remote for
debugging and run-time parameter adjustment

The software contributions are attributed as follows:

@li Code structure, high level architecture, and build system - Taylor Braun-Jones
@li Path planning algorithm and implementation - Logan Kinde
@li EEPROM reading and writing - Patrick McCarty
@li PWM motor controller - Michael Shelly

The rest of the code and the majority of the code base was developed between
Taylor and Logan together using the <a
href="http://en.wikipedia.org/wiki/Pair_programming">pair programming</a>
technique. These pieces include:

@li PID line tracking
@li Ball detection and seeking
@li Course traversal 
@li Ball collection maneuvers

@section acknowledgments Acknowledgments

This project was made possible by a generous $525 grant from the Cal Poly
Mechanical Engineering Student Fee Allocation Committee (MESFAC) and from
various part and monetary contributions of the the Cal Poly Robotics Club.

*/
