/**

@mainpage Introduction

@section problem_summary Problem Summary

Caddy is a robot that was entered into the 2005 Roborodentia
competition. Roborodentia is an annual autonomous robotics competition held
during Cal Poly's Open House by the Cal Poly Chapter of the IEEE Computer
Society. Robot entries must navigate a maze searching for three randomly
placed golf balls, collect them, and then deposit the balls in the “nest” at
the end of the maze. A newly added aspect for the 2005 competition included
two bonus balls that were placed on a platform behind the wall in two
predetermined corners of the maze. These platforms raised the bonus balls such
that the top of the golf ball was flush with the top of the wall.

@image html  arena.png "Arena map showing the two fixed bonus ball locations and the potential locations of the randomly placed ground balls"
@image latex arena.png "Arena map showing the two fixed bonus ball locations and the potential locations of the randomly placed ground balls" width=10cm

The competition scoring breakdown is as follows:

<table>
  <tr>
    <th>Point Value</th>
    <th>Task</th>
  </tr>
  <tr>
    <td>1</td>
    <td>Passing the first turn in the maze - Point A</td>
  </tr>
  <tr>
    <td>1</td>
    <td>Triggering “nest” solenoid by activating optical sensor - Point X</td>
  </tr>
  <tr>
    <td>3</td>
    <td>Touching each ground ball (1 point per ball)</td>
  </tr>
  <tr>
    <td>3</td>
    <td>Collecting and possessing each ground ball (1 point per ball)</td>
  </tr>
  <tr>
    <td>3</td>
    <td>Bringing each ground ball to the “nest” - Area B (1 point per ball)</td>
  </tr>
  <tr>
    <td>9</td>
    <td>Placing each ground ball in the “nest” - Point E (3 points per ball)</td>
  </tr>
  <tr>
    <td>10</td>
    <td>Collecting and possessing a bonus ball - 2 Yellow Balls (5 points per ball)</td>
  </tr>
  <tr>
    <td>6</td>
    <td>Placing a bonus ball in the “nest” (3 points per ball)</td>
  </tr>
  <tr>
    <td>36</td>
    <td>Total possible points</td>
  </tr>
</table>

In the case of a tie, the robot with the fastest time wins.

@htmlonly
<p>
The following sections document the Cal Poly Robotics Club entry "Caddy" for
the 2005 Roborodentia competition:
</p>
<ul>
<li><a href="goals.html">Goals</a></li>
<li><a href="design.html">Design</a></li>
<li><a href="conclusion.html">Conclusion</a></li>
<li><a href="appendix.html">Appendix</a></li>
</ul>

<p>
The content of this site is also available as a <a href="caddy.pdf">single pdf
report</a>.
</p>

@endhtmlonly

@page goals Goals and Requirements

The rules of the competition dictated a baseline set of requirements that
needed to be met in order to be successful:

@li <b>Line following</b> - The corridors of the maze were constructed with a
black electrical tape line down the center, meant as an aid for the autonomous
navigation of the pathways. We saw no reason not to take advantage of it.

@li <b>Junction detection</b> - To navigate the maze, Caddy would need the
ability to detect when a junction was reach and to identify the type of
junction (e.g. "T" junction, straight-or-right-turn junction, etc).

@li <b>Ground ball collection</b> - The maximum score without collecting any
ground ball is 5 out of 36 possible points - so a ground ball collection
system is a must to score well.

@li <b>Bonus ball collection</b> - Since the scoring distribution weighted
bonus balls so heavily (16 of the 36 possible points are awarded for bonus
ball tasks), we also decided that Caddy would need bonus ball collection
capability in order to be competitive.

@li <b>Ball release-into-nest system</b> - For an additional 3 points per
ball, having the ability to release balls into the nest seemed worthwhile and
comparatively simple to implement.

In addition to this baseline set of goals, we decided to focus on the
autonomous aspect of the Roborodentia competition. In particular we wanted a
robot that could <em>actively adapt</em> to the random ball locations, unlike
any previous entry had ever done. This was the driver for an additional two
requirements:

@li <b>Path planning</b> - Caddy needed a way to map the arena and a shortest
path algorithm that could find the best path through a sequence of goals.

@li <b>Ball finding</b> - To make the best use of the path planning algorithm,
we needed a way to actively search for balls down untraveled corridors.

@page design Design

@section team_process Collaborative Team Process

The team for this project was formed from interested members of the the
<a href="http://robotics.calpoly.edu/">Cal Poly Robotics Club</a>.

To organize the tasks and identify critical paths in the short project time
line, we used <a href="http://www.ganttproject.biz/">GanttProject</a> to
create a Gantt chart.

For code control and collaboration we used Concurrent Versions System
(CVS). Since this project had a competitive nature, we chose to setup and host
our own private CVS server rather than use a free, Internet-based hosting
service.

Between face-to-face team meetings we used Drupal to host a private forum for
discussing ideas, sharing progress, etc.

The inline code documentation and this project report were both managed using
<a href="http://doxygen.org">Doxygen</a>. Keeping the documentation in plain
text and means that the documentation can be version controlled the very same
way as the source code. The documentation also tends to stay more up to date
since it can be more conveniently updated at the same time as the source code.

@section system_arch System Architecture

When taking a holistic look at the project goals and requirements, it is
clear that a camera-based vision system can satisfy line following, junction
detection and ball-finding requirements. The image processing required for
these task can all be done with a camera that is low resolution, low power,
and low cost. The ball finding task, in particular, has few other options that
are both low cost and simple to implement. The <a
href="http://cmucam.org/projects/cmucam2">CMUcam2</a> developed by students
at Carnegie Mellon University and sold through distributors as a packaged
vision system, met our needs well.

Since the CMUcam can handle all the computationally intensive image processing
as well as drive 5 servo control outputs, our requirements on the main
microcontroller were fairly relaxed. The most computationally demanding task
for the main microcontroller is the shortest path algorithm, but with a
relatively small map even this could be handled by a low-end microcontroller.

@image html  electronics_block_diagram_dia.png "Electronics block diagram"
@image latex electronics_block_diagram_dia.eps "Electronics block diagram" width=12cm

@section electrical_design Electrical Design

@subsection power_motor Power Regulation and Motor Controller

We opted to design and build our own power regulation and motor control
circuitry over purchasing one of the more expensive off-the-shelf solutions.
To ensure that we were not debugging software and electrical issues at the
same time, we made sure to include robust regulation and decouple in the
design. Our power sub-component power needs were:

@li +5V regulated power for the ATMega32 and the rest of the electronics
@li +6-15V unregulated power for the CMUcam2
@li +6V for each motor, controllable via logic-level signal

Unregulated voltage was connected to the CMUcam2 (it had a built-in regulator)
and to the motors. Although not ideal, connecting the motors to unregulated
power meant we could save on cost by using a smaller, cheaper voltage
regulator. We opted for a linear regulator to supply the +5V to the ATMega32
microcontroller.

In the choice between a linear regulator and a switching regulator, a linear
was chosen over a switching regulator for the following reasons:

@li Lower output noise - We wanted to take every precaution we could to ensure
the EMF voltage generated by the motors did not affect the electronics.

@li Simpler to implement - Switching regulators typically require more passive
components to filter the inherently higher noise they generate.

@li Cheaper

Switching regulators are more efficient, however any efficiency gains would be
dwarfed in comparison with the power demands of the unregulated components (DC
motors and CMUcam2). The circuit diagram for our implementation is shown
below:

@image html  power_sch.png "Power regulation circuit"
@image latex power_sch.eps "Power regulation circuit" width=14cm

To control the motors via digital signal we used an H-bridge circuit. For
added protection of the electronics from the back-EMF voltage of the motors,
additional diodes were connected as shown in the schematic below.

@image html  motor_control_sch.png "Motor control circuit"
@image latex motor_control_sch.eps "Motor control circuit" width=17cm

The power regulation and motor control circuits were fabricated together on a
single board using a copper-plated board, etching solution, and a laser print
out of the circuit layout. We made sure to use polarized headers for all the
connections to avoid making any reverse polarity mistakes — though we still
managed to make a couple!.

@subsection wheel_encoders Wheel Encoders

@image html  mounted_encoders.png "Reflective IR sensors mounted on a bracket inside the left drive wheel"
@image latex mounted_encoders.png "Reflective IR sensors mounted on a bracket inside the left drive wheel" width=8cm

The maneuvers needed at junctions and for the bonus ball pick up sequences
needed to be accurate and repeatable. To achieve this we use a simple
differential drive system with encoders on each drive wheel. The encoders were
made up of reflective IR sensors pointed at black and white patterned disks
pasted to the inside edge of each drive wheel. @cite walters_dead_reckoning_2000

@image html  encoder_disc.png "48 segment pattern for reflective IR wheel encoders"
@image latex encoder_disc.png "48 segment pattern for reflective IR wheel encoders" width=6cm

The reflective IR sensors emit infrared light and measure the amount of
infrared light that is reflected back with a photodiode. Since the white
segments of the pattern reflect more light than the black segments, rotations
of the wheel can be detected by thresholding the measured IR signal level. To
guard against "chattering" when signals close to the threshold are applied a
dual-threshold Schmitt trigger is needed. The precision of this wheel encoder
system is equal to about one segment arc angle — 7.5° for a 48 segment
pattern.

The P5587 reflective IR sensor package chosen for Caddy was designed for
exactly this type of high contrast edge detection and so came with built in
Schmitt triggers and a logic-level output that could be easily read by a GPIO
input port on the microcontroller.

@subsection ir_break_beam IR Break Beam

In order to capture ground balls, Caddy needed a way to detect when a ball was
within the grasp of its lift mechanism.

We originally planned to use the centroid tracking feature of the camera since
the camera would always be facing down for line tracking during the times it
needed to detect ground balls. This turned out to be difficult mainly due to
the limitations of the camera. When the camera is configured to track a black
line both the glare from the overhead lighting and the randomly placed ground
have the same effect on what the camera detects – a gap in the line. We tried
to simply change modes whenever a gap was detected, determine if the gap was
due to a glare or a due to a ball, and then act accordingly. Unfortunately,
the CMUcam did not handle rapid mode and parameter changes well, taking too
long to switch from one mode to another. This lead to a failure in our
carefully tuned PID line tracking algorithm which relied on frequent, regular
updates over time. We considered and experimented with some ways of solving
this problem but none were the quick, elegant solution we were looking for.

With a fast approaching deadline, we opted for a quick, but less elegant,
solution. We installed an IR break beam sensor looking across the front of
the lift arm so that when the arm was down and fully open a ground ball would
break the beam as is passed under the arm.

@subsection servo_reverser Servo Reverser

The mechanical design of Caddy required 6 servos:

@li Ball pickup, left side
@li Ball pickup, right side
@li Boom control
@li Ball hopper
@li Tilt action
@li Pan action

This meant that the original plan to use the five servo control outputs of the
CMUcam would be inadequate.

The following approaches were considered for accommodating the 6th servo
output:

@li \b Mechanical: Modify the mechanical design so that the ball pickup
mechanism could be controlled by just one high-torque servo. The lift
mechanism had already been iteratively refined to the point that it could be
actuated by just one mechanical motion. Going this route would likely mean
some major rework of the mechanical design - not ideal since we were otherwise
happy with the mechanics of the robot.

@li \b Software: Use some of the extra pins on the ATmega32 to generate a
servo PWM signal. Unfortunately we were already using the two PWM peripherals
on the ATmega32 so we would have to do this in software. We had limited timer
resources on our chip and weren't sure how we might need to use them in the
future so this was not an ideal solution.

@li \b Electrical: Leverage the fact that the 2 servos controlling the ball
pickup were the same signal, 180 degrees out of phase. This seemed like a
perfect application for a simple 555 timer circuit.

Searching the Internet, we found we were not the only ones to think of using a
555 timer to create a servo reverser. Using the well documented plans from
C. Dane @cite dane_the_reverser we fabricated a board the size of a postage
stamp.

@section software_architecture Software Architecture and Algorithms

@subsection computing_platform Computing Platform

For our our computing platform we chose an ATmega32 microcontroller from
Atmel's 8-bit AVR line of microcontrollers because it was C-programmable with
free open-source tools and because we had a readily available development
board, the ERE EMBMega32.

@image html  ere_embmega32.png "EMBMega32 development board from ERE CO.,LTD"
@image latex ere_embmega32.png "EMBMega32 development board from ERE CO.,LTD" width=6cm

@subsection line_tracking PID Line Tracking

To track the black electrical tape line, we implemented a
proportional–integral–derivative (PID) controller. In PID theory, the output
of a PID controller, @f$c(t)@f$, is defined as:

@f[
c(t) = P_E e(t) + P_I \int e(t) dt + P_D \frac{de}{dt}
@f]

Where @f$ e(t) @f$ is some error function and @f$ P_E @f$, @f$ P_I @f$, and
@f$ P_D @f$ are adjustment coefficients for the observed error, the integrated
error and the derivative of the error, respectively. We define our error
term:

@f[
e(t) = \frac{dx}{dt}
@f]

By substitution, we get:

@f[
c(t) = P_E \frac{dx}{dt} + P_I x(t) + P_D \frac{d^2x}{dt^2}
@f]

Broken down and interpreted for the task of line tracking, these terms are:

@li @f$ P_E \frac{dx}{dt} \leftarrow @f$ How fast are we drifting from the center line?
@li @f$ P_I x(t) \leftarrow @f$ How far are we from from the center line?
@li @f$ P_D \frac{d^2x}{dt^2} \leftarrow @f$ How fast is the drift rate accelerating?

Provided that there is a way to measure or compute each of these terms, this
is a more robust form of the equation because it eliminates the integral term
which can cause problems due to accumulated error.

The figure below shows how the camera was used to measure @f$ P_E \frac{dx}{dt} @f$:

@image html  line_tracking_dia.png "Diagram of line tracking geometry (not to scale)"
@image latex line_tracking_dia.eps "Diagram of line tracking geometry (not to scale)" width=14cm

The drift rate is the slope of the black line with respect to the center line
of the robot. For points @f$ P_1 = (x_1,y_1) @f$ and @f$ P_2 = (x_2,y_2) @f$
from the diagram above we define:

@f[
\frac{dx}{dt} = \frac{y_2-y_1}{x_2-x_1}
@f]

And for point @f$ P_3 = (x_3,y_3) @f$ with constant, measurable value for @f$
y_3 @f$ and for constant, measurable line center @f$ x_{center} @f$

@f[
x_3 = x_{center} - \frac{dx}{dt} (y_3 - y_1) + x_1;
@f]

Lastly, by storing the previously computed value of @f$ \frac{dx}{dt} @f$, we can
compute the third term:

@f[
\frac{d^2x}{dt^2} = \frac{dx}{dt} - \frac{dx}{dt}_{previous}
@f]

The coefficients for each of these terms were determined by trial and error
using a tethered remote and stored persistently in EEPROM.

@subsection maneuvering Maneuvering

When turning our bot by a certain number of ticks, we experienced overshoot
despite actively applying DC motor braking. We addressed the problem with the
following software solution.

After turning for the desired number of ticks, we applied braking and counted
the number of excess ticks that occurred from the instant braking was
commanded. After a fixed delay, we drove the wheels in the opposite direction
for that same number of ticks.

This worked well for the most part, however, with different battery charges,
turn amounts, and turn types, the amount of time to brake was never the
same. If we did not brake the motors for a long enough delay, our bot would
stop counting excess ticks and begin to drive the motors in the opposite
direction, too soon. With our unsophisticated encoders that cannot detect the
direction of wheel motion this resulted in "reverse ticks" being counted
before the wheel had actually started moving in the reverse direction.

@subsection localization Localization

While the locations of the ground balls were not known a priori, the map of
the course was. We defined the course as a connected undirected graph with 42
nodes (vertices) as shown below. A node was placed at:

@li The start of the course
@li The end of the course
@li Every junction
@li Every potential ground ball location

@image html  arena_caddy.png "Caddy's connected graph representation of the arena"
@image latex arena_caddy.png "Caddy's connected graph representation of the arena" width=8cm

The software implementation of this graph was done using a C struct:

@code
typedef struct nodeStruct
{
    /** number of nodes adjacent to this node */
    uint8_t numAdjNodes;
    /** node numbers of adjacent nodes */
    uint8_t adjNodes[MAX_ADJ_NODES];
    /** distances to adjacent nodes (6 inches increments) */
    uint8_t adjCosts[MAX_ADJ_NODES];
    /** directions towards adjacent nodes (brads) */
    int8_t adjHeadings[MAX_ADJ_NODES];
} NODE;
@endcode

Each node defined the adjacent node numbers, directions, and distances to each
adjacent node. Headings were defined in units of 8-bit binary radians or
"brads". An 8-bit brad is 1/256 of a complete rotation. Brads are particularly
useful in that they leverage the inherent rollover digital adders to
automatically constrain the range of angular arithmetic operations to [0°
360°). Distances were stored using inches scaled by a factor of 1/6 since most
node-to-node distances were multiples of 6 inches. This allowed all distances
to be encoded in an 8-bit integer data type.

As an additional measure to conserve memory resources, information about the
type of node was encoded in the node number:

@li Node 0: Start
@li Node 1-20: Ball nodes
@li Node 21-41: Junction nodes
@li Node 42: End

SRAM memory was particularly limited on our ATMega32 platform, so to conserve
it for other uses, the node list was stored in FLASH using a switch statement
lookup table. This technique forces the constant values to be encoded in Load
Program Memory (LPM) instruction words which are stored and accessed directly
from FLASH.

@code
void getNode(uint8_t nodeNum, NODE *node)
{
    switch (nodeNum)
    {
    case 0:                          // START_NODE
        node->numAdjNodes = 1;
        node->   adjNodes[0] = 21;
        node->   adjCosts[0] = 9;
        node->adjHeadings[0] = -64;
        break;
    case 1:                          // First ball node
        node->numAdjNodes = 2;
        node->   adjNodes[0] = 21;
        node->   adjNodes[1] = 22;
        node->   adjCosts[0] = 4;
        node->   adjCosts[1] = 4;
        node->adjHeadings[0] = -128;
        node->adjHeadings[1] = 0;
        break;

    // ...

    case 42:                         // STOP_NODE
        node->numAdjNodes = 1;
        node->   adjNodes[0] = 41;
        node->   adjCosts[0] = 5;
        node->adjHeadings[0] = 0;
        break;
    }
@endcode

@subsection ball_detection Ball Detection

Except for a couple special cases, all ball detection was done at junctions
with the tilt servo oriented vertically and the panning servo oriented at a
fixed angle to the left or to the right. This covered all junctions in which a
ground ball could be located down a perpendicular corridor to the left or
right.

The ball detection algorithm was implemented using the built-in color tracking
and virtual window features of the CMUcam. As with the line tracking, it was
important that all the data processing intensive operations be done on the
CMUcam processor in order to achieve low execution time.

At every junction, Caddy traversed all connected nodes in the graph extending
to the left, for example. For any ground ball node encountered during this
graph traversal that had not yet been checked, the node number was recorded
along with distance away from the Caddy's current node location. If there was
at least one unchecked ball node to the left, Caddy would orient the camera
pan/tilt servos to look in that direction and use a sliding window algorithm
to search for the ball.

As shown in the diagram below, the ball detection algorithm searched for the
bottom of the ball by progressively moving a narrow image window through the
image and using an upper and lower color intensity thresholds to determine if
any orange pixels were within the image window.

@image html  ball_seek_left_view_dia.png "The camera's view while searching for a ball down a corridor to the left"
@image latex ball_seek_left_view_dia.eps "The camera's view while searching for a ball down a corridor to the left" width=10cm

If an orange pixel was found, a look-up table was used to convert the the
horizontal X coordinate of the image window to a physical distance away from
the bot. This distance was then compared with the values in the unchecked ball
list to find the most likely node number corresponding to the blob of orange
pixels.

@image html  ball_search_flowchart_dia.png "Perpendicular corridor ball searching flow chart"
@image latex ball_search_flowchart_dia.eps "Perpendicular corridor ball searching flow chart" width=10cm

Since stopping to perform these ball searches added time to the run we made
sure to mark any node that was "seen" during a ball search or physically
crossed by Caddy as having been checked. Also, once the final ground ball was
discovered all remaining unchecked nodes were marked as having been checked
(by process of elimination). These optimizations ensured that Caddy only
performed ball searches when necessary.

To optimize the computation time of the sliding window search algorithm, the
window width was increased from 1 pixel to 4 pixels. We found that this gave
sufficient resolution while providing a speedup of nearly 4.0. We also limited
the far end of the sliding window range to cover just six inches past the
farthest unchecked ball node since there was no point in search through parts
of the image which we knew would not offer any new information. With these
optimizations a typical ball search to the left or right took about 1 second.

@subsection path_planning Path Planning

The connected graph map of the arena and ball detection features described in
the previous sections provided pieces of information needed for a path
planning algorithm:

@li A map
@li A location
@li One or more destinations (goals)

Now, every time a goal was added to the goal list (i.e. a ground ball was
found), the path planning algorithm would compute the cost through all
permutations of known goals starting from the current node and ending at nest
node. This required two sub-algorithms:

@li A method to compute the shortest path between any two nodes
@li A method to compute all permutations of known goals

The permutation algorithm proved to be more challenging than originally
expected because the limited stack space of the ATmega32 precluded the use of
a recursive permutation algorithm. With some research we found a simple
iterative implementation in the GNU C++ Standard Template Library
(STL). Adapting this templated code to C99 C code we had a solution for
computing all permutations of any array of 8-bit values.

@page conclusion Conclusion

The overall design of the robot proved to be a success. Caddy was able to
perform all the tasks reliably and quickly. Unfortunately, the time
constraints of the Roborodentia competition meant that full implementation and
debugging of all the features was not completed until just @em after the
competition so Caddy did not rank as well as it could have.

The following section describes some of the technical aspects that, in
hindsight, we would have chosen to do differently.

@section future_work Future Work

@subsection regulated_motor_voltage Regulated Motor Voltage

If we end up working with higher voltage motors again, it may be worth the
added cost and decrease in power efficiency of regulating the motor
voltage. This allows for more consistent operation across fully charged and
partially charged batteries, especially with low precision wheel encoders that
do not sense direction.

@subsection pwm_motor_control PWM Motor Control using a 16-bit Timer

Since we were using timer 1 (a 16-bit timer) for PWM, we could have used
16-bit PWM. 8-bit resolution seemed to be sufficient with the original 6 volts
motors, but when we switched to 12 volt motors, more precise control of the
PWM signal would likely have improved the PID line tracking.

@subsection quadrature_wheel_encoders Quadrature Wheel Encoders

Quadrature wheel encoders would have required more mechanical work (to mount
the reflective IR sensors 90 degrees out-of-phase) and electrical work (wiring
for twice as many sensors) but it would have helped solve some challenges
with maneuvering the robot through precise sequences such as the bonus ball
pickup.

Quadrature encoders would have allowed us to perform overshoot correction
easily and accurately.

@page appendix Appendix

@section gantt Gantt Chart

@image html  caddy_gantt.png "Caddy project gantt chart"
@image latex caddy_gantt.png "Caddy project gantt chart" width=17cm

@htmlinclude reference.html

@section contributions Individual Contributions

Caddy was a joint effort between Taylor Braun-Jones, Logan Kinde, Tyson
Messori, Scott Barlow, Michael Shelley, and Patrick McCarty. Primary
contributors were Taylor Braun-Jones, Logan Kinde, and Tyson Messori.

@image html  team_photo_medium.png "Team Photo. Left to right: Logan Kinde, Tyson Messori, Taylor Braun-Jones, Scott Barlow, Michael Shelley, Patrick McCarty"
@image latex team_photo.png "Team Photo. Left to right: Logan Kinde, Tyson Messori, Taylor Braun-Jones, Scott Barlow, Michael Shelley, Patrick McCarty" width=12cm

@subsection taylor_contrib Contributions of Taylor Braun-Jones

Taylor was responsible for overall project coordination and administration
including:

@li Gantt chart creation and tracking
@li MESFAC grant proposal
@li Part ordering and budget management
@li Creation and administration of the code repository

Taylor's electrical and mechanical contributions include:

@li Custom-made battery packs from shrink wrap and five +1.2V rechargeable NiMH
AA batteries

@li The design and implementation of the bracket used to mount the CMUcam2 to
the panning servo

@li The concept and implementation of a detachable tethered remote for
debugging and run-time parameter adjustment

The software contributions are attributed as follows:

@li Code structure, high level architecture, and build system - Taylor Braun-Jones
@li Path planning algorithm and implementation - Logan Kinde
@li EEPROM reading and writing - Patrick McCarty
@li PWM motor controller - Michael Shelly

The rest of the code and the majority of the code base was developed between
Taylor and Logan together using the <a
href="http://en.wikipedia.org/wiki/Pair_programming">pair programming</a>
technique. These pieces include:

@li PID line tracking
@li Ball detection and seeking
@li Course traversal
@li Ball collection maneuvers

@section acknowledgments Acknowledgments

This project was made possible by a generous $525 grant from the Cal Poly
Mechanical Engineering Student Fee Allocation Committee (MESFAC) and from
various part and monetary contributions of the the Cal Poly Robotics Club.

*/
